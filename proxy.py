import requests
import yaml
import re
from datetime import datetime
import collections
import time
import json
import os

# å®šä¹‰è¦ä¸‹è½½çš„ YAML é…ç½®æ–‡ä»¶ URLsï¼ˆæœ€è¿‘ç»å¸¸æ›´æ–°çš„Clashè®¢é˜…æºï¼‰"https://raw.githubusercontent.com/Ruk1ng001/freeSub/main/clash.yaml",
urls = [
    "https://raw.githubusercontent.com/Barabama/FreeNodes/main/nodes/wenode.yaml",
    "https://raw.githubusercontent.com/SnapdragonLee/SystemProxy/master/dist/clash_config.yaml",
    "https://raw.githubusercontent.com/firefoxmmx2/v2rayshare_subcription/main/subscription/clash_sub.yaml",
    "https://github.com/telegeam/freenode/blob/master/clash.yaml",
    "https://raw.githubusercontent.com/free18/v2ray/refs/heads/main/c.yaml",
    "https://raw.githubusercontent.com/adiwzx/freenode/main/adispeed.yml"
]

# åŠ¨æ€è·å– hongkongclash ä»“åº“æœ€æ–°æ—¥æœŸçš„æ‰€æœ‰ YAML æ–‡ä»¶ï¼ˆæ‰©å±•å›é€€åˆ°æœ€è¿‘12ä¸ªæœˆï¼‰
def get_latest_hongkongclash_yaml():
    year = datetime.now().year
    month = datetime.now().month
    attempts = 0
    max_attempts = 12  # å°è¯•æœ€è¿‘12ä¸ªæœˆ
    while attempts < max_attempts:
        dir_path = f"uploads/{year}/{month:02d}"
        api_url = f"https://api.github.com/repos/hongkongclash/hongkongclash.github.io/contents/{dir_path}?ref=main"
        
        try:
            response = requests.get(api_url)
            if response.status_code == 200:
                files = [f for f in response.json() if isinstance(f, dict) and f['name'].endswith('.yaml')]
                if files:
                    # æå–æ—¥æœŸå¹¶è·å–æœ€æ–°
                    date_pattern = re.compile(r'^\d+-(\d{8})\.yaml$')
                    dates = [match.group(1) for f in files if (match := date_pattern.match(f['name']))]
                    if dates:
                        latest_date = max(dates)
                        latest_files = sorted([f for f in files if f['name'].endswith(f'{latest_date}.yaml')], key=lambda x: x['name'])
                        raw_urls = [f"https://raw.githubusercontent.com/hongkongclash/hongkongclash.github.io/main/{dir_path}/{f['name']}" for f in latest_files]
                        print(f"Found hongkongclash YAML files in {dir_path} for {latest_date}: {len(raw_urls)} files")
                        return raw_urls
            print(f"No files in {dir_path}, trying previous month...")
        except requests.RequestException as e:
            print(f"Error fetching {dir_path}: {e}")
        
        # å›é€€
        month -= 1
        if month == 0:
            month = 12
            year -= 1
        attempts += 1
    
    print("No YAML files found in recent 12 months")
    return []

# è·å–å¹¶æ‰“å°æ‰€æœ‰è®¢é˜…é“¾æ¥
print("=== Acquired Clash Subscription URLs ===")
for i, url in enumerate(urls, 1):
    print(f"URL {i}: {url}")
latest_hongkongclash_urls = get_latest_hongkongclash_yaml()
if latest_hongkongclash_urls:
    urls.extend(latest_hongkongclash_urls)
    for i, url in enumerate(latest_hongkongclash_urls, len(urls) - len(latest_hongkongclash_urls) + 1):
        print(f"URL {i}: {url}")
print(f"Total URLs: {len(urls)}")
print("======================================")

# è¾“å‡ºæ‰€æœ‰èŠ‚ç‚¹æ–‡ä»¶é“¾æ¥åˆ° node_urls.txt
with open('node_urls.txt', 'w', encoding='utf-8') as urlfile:
    for url in urls:
        urlfile.write(url + '\n')
print(f"Node URLs saved to node_urls.txt: {len(urls)} links")

# ç¡®ä¿ç”Ÿæˆç©ºçš„ valid_proxies.yamlï¼ˆå¦‚æœ LiteSpeedTest æœªè¿è¡Œï¼‰
with open('valid_proxies.yaml', 'w', encoding='utf-8') as outfile:
    yaml.dump({'proxies': []}, outfile, default_flow_style=False, allow_unicode=True, sort_keys=False)

# å®šä¹‰ä»£ç†ç­›é€‰å‡½æ•°
def valid_proxy(proxy):
    name = proxy.get('name', '')
    proxy_type = proxy.get('type', '').lower()
    banned_keywords = ['CN', 'AE','File']
    banned_types = ['http']
    
    required_fields = {
        'ss': ['server', 'port', 'cipher', 'password'],
        'trojan': ['server', 'port', 'password'],
        'vmess': ['server', 'port', 'uuid', 'alterId', 'cipher'],
        'hysteria2': ['server', 'port', 'password'],  # æ”¯æŒ Hysteria2
        'vless': ['server', 'port', 'uuid']  # æ”¯æŒ Vless (ç®€åŒ–å­—æ®µ)
    }
    
    if proxy_type not in required_fields:
        print(f"Unsupported proxy type: {proxy_type}")
        return False
    for field in required_fields[proxy_type]:
        if field not in proxy or proxy[field] is None or proxy[field] == '':
            print(f"Missing required field '{field}' for {proxy_type} proxy: {name}")
            return False
    
    return (
        not any(keyword in name for keyword in banned_keywords) and
        proxy_type not in banned_types
    )

# å¤„ç† LiteSpeedTest ç»“æœ
if os.path.exists('lite_valid_proxies.json'):
    print("\n=== Processing LiteSpeedTest Valid Proxies ===")
    try:
        with open('lite_valid_proxies.json', 'r') as f:
            all_valid_proxies = json.load(f)
    except json.JSONDecodeError as e:
        print(f"Error decoding lite_valid_proxies.json: {e}")
        all_valid_proxies = []
    
    # è¿‡æ»¤æ— æ•ˆä»£ç†
    filtered_proxies = [proxy for proxy in all_valid_proxies if valid_proxy(proxy)]
    print(f"Filtered proxies: {len(filtered_proxies)} / {len(all_valid_proxies)} (removed invalid)")
    
    print("\n=== Valid Proxies from LiteSpeedTest ===")
    for i, proxy in enumerate(filtered_proxies, 1):
        print(f"Proxy {i}:")
        print(f"  Name: {proxy.get('name', 'Unknown')}")
        print(f"  Type: {proxy.get('type', 'Unknown')}")
        print(f"  Server: {proxy.get('server', 'Unknown')}")
        print(f"  Port: {proxy.get('port', 'Unknown')}")
        print(f"  Latency: {proxy.get('latency_ms', 'N/A')}ms")
        print(f"  Max Speed: {proxy.get('max_speed', 'N/A')}")
        print(f"  Additional Fields: {', '.join(f'{k}={v}' for k, v in proxy.items() if k not in ['name', 'type', 'server', 'port', 'latency_ms', 'max_speed'])}")
    print(f"Total Valid Proxies: {len(filtered_proxies)}")
    print("======================================")

    # å›½å®¶ä¸å›½æ——æ˜ å°„ (ç®€åŒ–ç‰ˆï¼Œå®Œæ•´åˆ—è¡¨å¦‚ä¹‹å‰)
    country_flags = {
        'ç¾å›½': ('ğŸ‡ºğŸ‡¸', 'US'), 'åŠ æ‹¿å¤§': ('ğŸ‡¨ğŸ‡¦', 'CA'), 'è‹±å›½': ('ğŸ‡¬ğŸ‡§', 'GB'), 'æ¾³å¤§åˆ©äºš': ('ğŸ‡¦ğŸ‡º', 'AU'),
        'å¾·å›½': ('ğŸ‡©ğŸ‡ª', 'DE'), 'æ³•å›½': ('ğŸ‡«ğŸ‡·', 'FR'), 'æ„å¤§åˆ©': ('ğŸ‡®ğŸ‡¹', 'IT'), 'è¥¿ç­ç‰™': ('ğŸ‡ªğŸ‡¸', 'ES'),
        'è·å…°': ('ğŸ‡³ğŸ‡±', 'NL'), 'ç‘å…¸': ('ğŸ‡¸ğŸ‡ª', 'SE'), 'æŒªå¨': ('ğŸ‡³ğŸ‡´', 'NO'), 'ä¸¹éº¦': ('ğŸ‡©ğŸ‡°', 'DK'),
        'èŠ¬å…°': ('ğŸ‡«ğŸ‡®', 'FI'), 'ç‘å£«': ('ğŸ‡¨ğŸ‡­', 'CH'), 'æ¯”åˆ©æ—¶': ('ğŸ‡§ğŸ‡ª', 'BE'), 'å¥¥åœ°åˆ©': ('ğŸ‡¦ğŸ‡¹', 'AT'),
        'çˆ±å°”å…°': ('ğŸ‡®ğŸ‡ª', 'IE'), 'æ–°è¥¿å…°': ('ğŸ‡³ğŸ‡¿', 'NZ'), 'å—é': ('ğŸ‡¿ğŸ‡¦', 'ZA'), 'å°åº¦': ('ğŸ‡®ğŸ‡³', 'IN'),
        'ä¸­å›½': ('ğŸ‡¨ğŸ‡³', 'CN'), 'ä¸­å›½å¤§é™†': ('ğŸ‡¨ğŸ‡³', 'CN'), 'æ—¥æœ¬': ('ğŸ‡¯ğŸ‡µ', 'JP'), 'éŸ©å›½': ('ğŸ‡°ğŸ‡·', 'KR'),
        'æ–°åŠ å¡': ('ğŸ‡¸ğŸ‡¬', 'SG'), 'é©¬æ¥è¥¿äºš': ('ğŸ‡²ğŸ‡¾', 'MY'), 'æ³°å›½': ('ğŸ‡¹ğŸ‡­', 'TH'), 'è¶Šå—': ('ğŸ‡»ğŸ‡³', 'VN'),
        'å°åº¦å°¼è¥¿äºš': ('ğŸ‡®ğŸ‡©', 'ID'), 'è²å¾‹å®¾': ('ğŸ‡µğŸ‡­', 'PH'), 'å·´è¥¿': ('ğŸ‡§ğŸ‡·', 'BR'), 'é˜¿æ ¹å»·': ('ğŸ‡¦ğŸ‡·', 'AR'),
        'å¢¨è¥¿å“¥': ('ğŸ‡²ğŸ‡½', 'MX'), 'ä¿„ç½—æ–¯': ('ğŸ‡·ğŸ‡º', 'RU'), 'åœŸè€³å…¶': ('ğŸ‡¹ğŸ‡·', 'TR'), 'æ²™ç‰¹é˜¿æ‹‰ä¼¯': ('ğŸ‡¸ğŸ‡¦', 'SA'),
        'é˜¿è”é…‹': ('ğŸ‡¦ğŸ‡ª', 'AE'), 'åŸƒåŠ': ('ğŸ‡ªğŸ‡¬', 'EG'), 'ä»¥è‰²åˆ—': ('ğŸ‡®ğŸ‡±', 'IL'), 'å¸Œè…Š': ('ğŸ‡¬ğŸ‡·', 'GR'),
        'è‘¡è„ç‰™': ('ğŸ‡µğŸ‡¹', 'PT'), 'æ·å…‹å…±å’Œå›½': ('ğŸ‡¨ğŸ‡¿', 'CZ'), 'åŒˆç‰™åˆ©': ('ğŸ‡­ğŸ‡º', 'HU'), 'æ–¯æ´›ä¼å…‹å…±å’Œå›½': ('ğŸ‡¸ğŸ‡°', 'SK'),
        'é¦™æ¸¯': ('ğŸ‡­ğŸ‡°', 'HK'), 'å°æ¹¾': ('ğŸ‡¹ğŸ‡¼', 'TW'), 'æ¾³é—¨': ('ğŸ‡²ğŸ‡´', 'MO'), 'æ³¢å…°': ('ğŸ‡µğŸ‡±', 'PL'),
        'ä¹Œå…‹å…°': ('ğŸ‡ºğŸ‡¦', 'UA'), 'ç½—é©¬å°¼äºš': ('ğŸ‡·ğŸ‡´', 'RO'), 'å¡å°”ç»´äºš': ('ğŸ‡·ğŸ‡¸', 'RS')
    }
    unknown_country = ('â“', 'UNK')

    ip_cache = {}

    def get_country_from_ip(servers):
        result = {}
        to_query = [server for server in servers if server not in ip_cache]
        if not to_query:
            return {server: ip_cache[server] for server in servers}

        for i in range(0, len(to_query), 100):
            batch = to_query[i:i+100]
            batch_query = [{"query": server} for server in batch]
            for attempt in range(3):
                try:
                    response = requests.post("http://ip-api.com/batch", json=batch_query)
                    response.raise_for_status()
                    data = response.json()
                    for query, server in zip(data, batch):
                        if query.get('status') == 'success':
                            country_code = query.get('countryCode')
                            for country, (flag, code) in country_flags.items():
                                if code == country_code:
                                    ip_cache[server] = (flag, country)
                                    result[server] = (flag, country)
                                    break
                            else:
                                ip_cache[server] = (unknown_country[0], 'æœªçŸ¥')
                                result[server] = (unknown_country[0], 'æœªçŸ¥')
                        else:
                            print(f"Query failed for {server}: {query.get('message', 'Unknown error')}")
                            ip_cache[server] = (unknown_country[0], 'æœªçŸ¥')
                            result[server] = (unknown_country[0], 'æœªçŸ¥')
                    break
                except requests.RequestException as e:
                    print(f"Batch query attempt {attempt+1}/3 failed: {e}")
                    time.sleep(3)  # å¢åŠ é‡è¯•å»¶è¿Ÿï¼Œé¿å…é€Ÿç‡é™åˆ¶
                    if attempt == 2:
                        for server in batch:
                            ip_cache[server] = (unknown_country[0], 'æœªçŸ¥')
                            result[server] = (unknown_country[0], 'æœªçŸ¥')
        
        for server in servers:
            if server not in result:
                result[server] = ip_cache[server]
        return result

    # åˆå¹¶æœ‰æ•ˆä»£ç†
    merged_proxies = []
    name_counter = {}
    seen_proxies = set()

    servers_to_query = set()
    proxy_info = []
    for proxy in filtered_proxies:  # ä½¿ç”¨è¿‡æ»¤åçš„ proxies
        name = proxy.get('name', '')
        server = proxy.get('server', '')
        # æ”¶é›†æ‰€æœ‰ server ç”¨äºæ‰¹é‡ IP æŸ¥è¯¢
        servers_to_query.add(server)
        proxy_info.append({
            'proxy': proxy,
            'name': name,
            'server': server
        })

    # æ‰¹é‡æŸ¥è¯¢ IP å›½å®¶
    server_countries = get_country_from_ip(list(servers_to_query))

    for info in proxy_info:
        proxy = info['proxy']
        name = info['name']
        server = info['server']
        # ä¼˜å…ˆ IP æŸ¥è¯¢
        server_country = server_countries.get(server, None)
        if server_country and server_country[1] != 'æœªçŸ¥':
            flag, country_key = server_country
        else:
            # fallback åˆ°å…³é”®è¯åŒ¹é…
            matched = False
            flag = unknown_country[0]
            country_key = 'æœªçŸ¥'
            for country, (f, code) in country_flags.items():
                if country in name or code in name:
                    matched = True
                    flag = f
                    country_key = country
                    break
            if not matched:
                flag, country_key = unknown_country

        if country_key not in name_counter:
            name_counter[country_key] = 1
        else:
            name_counter[country_key] += 1
        new_name = f"{flag} {str(name_counter[country_key]).zfill(3)}"
        
        ordered_proxy = collections.OrderedDict()
        ordered_proxy['name'] = new_name
        ordered_proxy['type'] = proxy['type']
        ordered_proxy['server'] = proxy['server']
        ordered_proxy['port'] = proxy['port']
        
        # å¤åˆ¶æ‰€æœ‰åŸå§‹å­—æ®µï¼Œé™¤äº† name/type/server/port (ä¿ç•™æµ‹è¯•å­—æ®µå¦‚ latency_ms)
        additional_fields = {k: v for k, v in proxy.items() if k not in ['name', 'type', 'server', 'port']}
        sorted_additional = sorted(additional_fields.items())
        for key, value in sorted_additional:
            ordered_proxy[key] = value
        
        proxy_key = (ordered_proxy['server'], ordered_proxy['port'], ordered_proxy['type'])
        if proxy_key not in seen_proxies:
            seen_proxies.add(proxy_key)
            merged_proxies.append(dict(ordered_proxy))

    with open('valid_proxies.yaml', 'w', encoding='utf-8') as outfile:
        yaml.dump({'proxies': merged_proxies}, outfile, default_flow_style=False, allow_unicode=True, sort_keys=False)

    print(f"Valid proxy configurations have been successfully processed and saved to valid_proxies.yaml ({len(merged_proxies)} proxies).")
else:
    print("No lite_valid_proxies.json found; generating empty valid_proxies.yaml.")
